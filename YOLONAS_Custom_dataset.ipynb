{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IndraTensei/testbot/blob/main/YOLONAS_Custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m0SkK3bjMOqH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "242e70e5-4d33-404d-8df5-42e21be460e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting super-gradients\n",
            "  Downloading super_gradients-3.3.0-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (4.66.1)\n",
            "Collecting boto3>=1.17.15 (from super-gradients)\n",
            "  Using cached boto3-1.28.66-py3-none-any.whl (135 kB)\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (4.19.1)\n",
            "Collecting Deprecated>=1.2.11 (from super-gradients)\n",
            "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: opencv-python>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (4.8.0.76)\n",
            "Requirement already satisfied: scipy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (1.11.3)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (3.7.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (5.9.5)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (2.13.0)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (67.7.2)\n",
            "Collecting coverage~=5.3.1 (from super-gradients)\n",
            "  Using cached coverage-5.3.1-cp310-cp310-linux_x86_64.whl\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (0.15.2+cu118)\n",
            "Collecting sphinx~=4.0.2 (from super-gradients)\n",
            "  Using cached Sphinx-4.0.3-py3-none-any.whl (2.9 MB)\n",
            "Collecting sphinx-rtd-theme (from super-gradients)\n",
            "  Using cached sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
            "Collecting torchmetrics==0.8 (from super-gradients)\n",
            "  Using cached torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n",
            "Collecting hydra-core>=1.2.0 (from super-gradients)\n",
            "  Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Collecting omegaconf (from super-gradients)\n",
            "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Collecting onnxruntime==1.13.1 (from super-gradients)\n",
            "  Using cached onnxruntime-1.13.1-cp310-cp310-manylinux_2_27_x86_64.whl (4.5 MB)\n",
            "Collecting onnx==1.13.0 (from super-gradients)\n",
            "  Using cached onnx-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "Requirement already satisfied: pillow!=8.3,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (9.4.0)\n",
            "Requirement already satisfied: pip-tools>=6.12.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (6.13.0)\n",
            "Collecting pyparsing==2.4.5 (from super-gradients)\n",
            "  Using cached pyparsing-2.4.5-py2.py3-none-any.whl (67 kB)\n",
            "Collecting einops==0.3.2 (from super-gradients)\n",
            "  Using cached einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Collecting pycocotools==2.0.6 (from super-gradients)\n",
            "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (3.20.3)\n",
            "Collecting treelib==1.6.1 (from super-gradients)\n",
            "  Using cached treelib-1.6.1-py3-none-any.whl\n",
            "Collecting termcolor==1.1.0 (from super-gradients)\n",
            "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (23.2)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (0.41.2)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients) (2.16.1)\n",
            "Collecting stringcase>=1.2.0 (from super-gradients)\n",
            "  Using cached stringcase-1.2.0-py3-none-any.whl\n",
            "Collecting numpy<=1.23 (from super-gradients)\n",
            "  Using cached numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "Collecting rapidfuzz (from super-gradients)\n",
            "  Using cached rapidfuzz-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "Collecting json-tricks==3.16.1 (from super-gradients)\n",
            "  Using cached json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting onnx-simplifier<1.0,>=0.3.6 (from super-gradients)\n",
            "  Using cached onnx_simplifier-0.4.33-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Collecting data-gradients>=0.2.0 (from super-gradients)\n",
            "  Downloading data_gradients-0.2.1-py3-none-any.whl (454 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx==1.13.0->super-gradients) (4.5.0)\n",
            "Collecting coloredlogs (from onnxruntime==1.13.1->super-gradients)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->super-gradients) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->super-gradients) (1.12)\n",
            "Collecting pyDeprecate==0.3.* (from torchmetrics==0.8->super-gradients)\n",
            "  Using cached pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from treelib==1.6.1->super-gradients) (0.18.3)\n",
            "Collecting botocore<1.32.0,>=1.31.66 (from boto3>=1.17.15->super-gradients)\n",
            "  Using cached botocore-1.31.66-py3-none-any.whl (11.3 MB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.17.15->super-gradients)\n",
            "  Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3>=1.17.15->super-gradients)\n",
            "  Using cached s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from data-gradients>=0.2.0->super-gradients) (3.11.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from data-gradients>=0.2.0->super-gradients) (0.12.2)\n",
            "Collecting xhtml2pdf (from data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading xhtml2pdf-0.2.11.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from data-gradients>=0.2.0->super-gradients) (3.1.2)\n",
            "Collecting imagededup (from data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading imagededup-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated>=1.2.11->super-gradients) (1.15.0)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.2.0->super-gradients)\n",
            "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients) (0.10.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients) (0.10.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients) (1.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients) (2.8.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf->super-gradients) (6.0.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier<1.0,>=0.3.6->super-gradients) (13.6.0)\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients) (1.0.3)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients) (8.1.7)\n",
            "Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients) (23.1.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.0.6)\n",
            "Collecting docutils<0.18,>=0.14 (from sphinx~=4.0.2->super-gradients)\n",
            "  Using cached docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (2.13.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients) (2.31.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (3.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients) (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients) (3.12.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->super-gradients) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->super-gradients) (17.0.2)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->super-gradients)\n",
            "  Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.66->boto3>=1.17.15->super-gradients) (2.0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cycler>=0.10->matplotlib>=3.3.4->super-gradients) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->super-gradients) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->data-gradients>=0.2.0->super-gradients) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (2022.12.7)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build->pip-tools>=6.12.1->super-gradients) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build->pip-tools>=6.12.1->super-gradients) (2.0.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.13.1->super-gradients)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients>=0.2.0->super-gradients) (1.2.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients>=0.2.0->super-gradients) (1.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier<1.0,>=0.3.6->super-gradients) (3.0.0)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn->data-gradients>=0.2.0->super-gradients) (1.5.3)\n",
            "INFO: pip is looking at multiple versions of sphinxcontrib-applehelp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinxcontrib-applehelp (from sphinx~=4.0.2->super-gradients)\n",
            "  Using cached sphinxcontrib_applehelp-1.0.6-py3-none-any.whl (120 kB)\n",
            "  Using cached sphinxcontrib_applehelp-1.0.5-py3-none-any.whl (120 kB)\n",
            "  Using cached sphinxcontrib_applehelp-1.0.4-py3-none-any.whl (120 kB)\n",
            "INFO: pip is looking at multiple versions of sphinxcontrib-devhelp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinxcontrib-devhelp (from sphinx~=4.0.2->super-gradients)\n",
            "  Using cached sphinxcontrib_devhelp-1.0.4-py3-none-any.whl (83 kB)\n",
            "  Using cached sphinxcontrib_devhelp-1.0.3-py3-none-any.whl (83 kB)\n",
            "  Using cached sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
            "INFO: pip is looking at multiple versions of sphinxcontrib-htmlhelp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinxcontrib-htmlhelp (from sphinx~=4.0.2->super-gradients)\n",
            "  Using cached sphinxcontrib_htmlhelp-2.0.3-py3-none-any.whl (99 kB)\n",
            "  Using cached sphinxcontrib_htmlhelp-2.0.2-py3-none-any.whl (99 kB)\n",
            "  Using cached sphinxcontrib_htmlhelp-2.0.1-py3-none-any.whl (99 kB)\n",
            "INFO: pip is looking at multiple versions of sphinxcontrib-qthelp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinxcontrib-qthelp (from sphinx~=4.0.2->super-gradients)\n",
            "  Using cached sphinxcontrib_qthelp-1.0.5-py3-none-any.whl (89 kB)\n",
            "  Using cached sphinxcontrib_qthelp-1.0.4-py3-none-any.whl (89 kB)\n",
            "  Using cached sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
            "INFO: pip is looking at multiple versions of sphinxcontrib-serializinghtml to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinxcontrib-serializinghtml (from sphinx~=4.0.2->super-gradients)\n",
            "  Using cached sphinxcontrib_serializinghtml-1.1.8-py3-none-any.whl (92 kB)\n",
            "  Using cached sphinxcontrib_serializinghtml-1.1.7-py3-none-any.whl (92 kB)\n",
            "  Using cached sphinxcontrib_serializinghtml-1.1.6-py3-none-any.whl (92 kB)\n",
            "  Using cached sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.13.1->super-gradients) (1.3.0)\n",
            "Collecting arabic-reshaper>=3.0.0 (from xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: html5lib>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf->data-gradients>=0.2.0->super-gradients) (1.1)\n",
            "Collecting pyHanko>=0.12.1 (from xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading pyHanko-0.20.1-py3-none-any.whl (407 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.7/407.7 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyhanko-certvalidator>=0.19.5 (from xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading pyhanko_certvalidator-0.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf>=3.1.0 (from xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading pypdf-3.16.4-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-bidi>=0.4.2 (from xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Collecting reportlab<4,>=3.5.53 (from xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading reportlab-3.6.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting svglib>=1.2.1 (from xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading svglib-1.5.1.tar.gz (913 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.9/913.9 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.0.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients) (0.5.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier<1.0,>=0.3.6->super-gradients) (0.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn->data-gradients>=0.2.0->super-gradients) (2023.3.post1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients) (0.5.0)\n",
            "Collecting asn1crypto>=1.5.1 (from pyHanko>=0.12.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qrcode>=6.1 (from pyHanko>=0.12.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading qrcode-7.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tzlocal>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients) (5.1)\n",
            "Collecting pyhanko-certvalidator>=0.19.5 (from xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading pyhanko_certvalidator-0.24.1-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients) (41.0.4)\n",
            "Collecting oscrypto>=1.1.0 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uritools>=3.0.1 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading uritools-4.0.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->super-gradients) (3.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients) (4.9.3)\n",
            "Requirement already satisfied: tinycss2>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients) (1.2.1)\n",
            "Collecting cssselect2>=0.2.0 (from svglib>=1.2.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients>=0.2.0->super-gradients) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients>=0.2.0->super-gradients) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3.1->pyHanko>=0.12.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients) (1.16.0)\n",
            "Collecting pypng (from qrcode>=6.1->pyHanko>=0.12.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients)\n",
            "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3.1->pyHanko>=0.12.1->xhtml2pdf->data-gradients>=0.2.0->super-gradients) (2.21)\n",
            "Building wheels for collected packages: pycocotools, xhtml2pdf, svglib\n",
            "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=376856 sha256=aa36760a26a3437a67a01f77ff9e712745f0d7a23cbf2ab8f9ea691d63e3873b\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/e6/f9/f87c8f8be098b51b616871315318329cae12cdb618f4caac93\n",
            "  Building wheel for xhtml2pdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xhtml2pdf: filename=xhtml2pdf-0.2.11-py3-none-any.whl size=262644 sha256=e6e76a213b7c658bd4ea9da3f90b4fb63230970c49f0e12962422ebc43a6df14\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/77/fb/e473c11c4e30a7680bf5b1b7f1d07ef04932184a2f39118e8d\n",
            "  Building wheel for svglib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for svglib: filename=svglib-1.5.1-py3-none-any.whl size=30904 sha256=dfc538cbf7d7b90a4f262de0e111c47496ee2563e8b9f46c6854fc39993bf582\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/9f/90/f37f4b9dbf82987a24ae14f15586e96715cb669a4710b3b85d\n",
            "Successfully built pycocotools xhtml2pdf svglib\n",
            "Installing collected packages: termcolor, stringcase, pypng, json-tricks, einops, asn1crypto, arabic-reshaper, antlr4-python3-runtime, uritools, treelib, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, reportlab, rapidfuzz, qrcode, python-bidi, pypdf, pyparsing, pyDeprecate, oscrypto, omegaconf, numpy, jmespath, humanfriendly, docutils, Deprecated, coverage, sphinx, onnx, hydra-core, cssselect2, coloredlogs, botocore, svglib, sphinxcontrib-jquery, s3transfer, pyhanko-certvalidator, onnxruntime, onnx-simplifier, sphinx-rtd-theme, pyHanko, pycocotools, boto3, xhtml2pdf, imagededup, torchmetrics, data-gradients, super-gradients\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.3.0\n",
            "    Uninstalling termcolor-2.3.0:\n",
            "      Successfully uninstalled termcolor-2.3.0\n",
            "  Attempting uninstall: sphinxcontrib-serializinghtml\n",
            "    Found existing installation: sphinxcontrib-serializinghtml 1.1.9\n",
            "    Uninstalling sphinxcontrib-serializinghtml-1.1.9:\n",
            "      Successfully uninstalled sphinxcontrib-serializinghtml-1.1.9\n",
            "  Attempting uninstall: sphinxcontrib-qthelp\n",
            "    Found existing installation: sphinxcontrib-qthelp 1.0.6\n",
            "    Uninstalling sphinxcontrib-qthelp-1.0.6:\n",
            "      Successfully uninstalled sphinxcontrib-qthelp-1.0.6\n",
            "  Attempting uninstall: sphinxcontrib-htmlhelp\n",
            "    Found existing installation: sphinxcontrib-htmlhelp 2.0.4\n",
            "    Uninstalling sphinxcontrib-htmlhelp-2.0.4:\n",
            "      Successfully uninstalled sphinxcontrib-htmlhelp-2.0.4\n",
            "  Attempting uninstall: sphinxcontrib-devhelp\n",
            "    Found existing installation: sphinxcontrib-devhelp 1.0.5\n",
            "    Uninstalling sphinxcontrib-devhelp-1.0.5:\n",
            "      Successfully uninstalled sphinxcontrib-devhelp-1.0.5\n",
            "  Attempting uninstall: sphinxcontrib-applehelp\n",
            "    Found existing installation: sphinxcontrib-applehelp 1.0.7\n",
            "    Uninstalling sphinxcontrib-applehelp-1.0.7:\n",
            "      Successfully uninstalled sphinxcontrib-applehelp-1.0.7\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 2.4.7\n",
            "    Uninstalling pyparsing-2.4.7:\n",
            "      Successfully uninstalled pyparsing-2.4.7\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 5.0.2\n",
            "    Uninstalling Sphinx-5.0.2:\n",
            "      Successfully uninstalled Sphinx-5.0.2\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.7\n",
            "    Uninstalling pycocotools-2.0.7:\n",
            "      Successfully uninstalled pycocotools-2.0.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "roboflow 1.1.7 requires pyparsing==2.4.7, but you have pyparsing 2.4.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 antlr4-python3-runtime-4.9.3 arabic-reshaper-3.0.0 asn1crypto-1.5.1 boto3-1.28.66 botocore-1.31.66 coloredlogs-15.0.1 coverage-5.3.1 cssselect2-0.7.0 data-gradients-0.2.1 docutils-0.17.1 einops-0.3.2 humanfriendly-10.0 hydra-core-1.3.2 imagededup-0.3.2 jmespath-1.0.1 json-tricks-3.16.1 numpy-1.23.0 omegaconf-2.3.0 onnx-1.13.0 onnx-simplifier-0.4.33 onnxruntime-1.13.1 oscrypto-1.3.0 pyDeprecate-0.3.2 pyHanko-0.20.1 pycocotools-2.0.6 pyhanko-certvalidator-0.24.1 pyparsing-2.4.5 pypdf-3.16.4 pypng-0.20220715.0 python-bidi-0.4.2 qrcode-7.4.2 rapidfuzz-3.4.0 reportlab-3.6.13 s3transfer-0.7.0 sphinx-4.0.3 sphinx-rtd-theme-1.3.0 sphinxcontrib-applehelp-1.0.4 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.1 sphinxcontrib-jquery-4.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 stringcase-1.2.0 super-gradients-3.3.0 svglib-1.5.1 termcolor-1.1.0 torchmetrics-0.8.0 treelib-1.6.1 uritools-4.0.2 xhtml2pdf-0.2.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pydevd_plugins",
                  "pyparsing",
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.7)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.0)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.6)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.1.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.43.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.3)\n",
            "Installing collected packages: pyparsing\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 2.4.5\n",
            "    Uninstalling pyparsing-2.4.5:\n",
            "      Successfully uninstalled pyparsing-2.4.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "super-gradients 3.3.0 requires pyparsing==2.4.5, but you have pyparsing 2.4.7 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pyparsing-2.4.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n"
          ]
        }
      ],
      "source": [
        "# py -3.10 -m venv myvenv\n",
        "# myvenv\\Scripts\\activate\n",
        "\n",
        "\n",
        "!pip install super-gradients\n",
        "!pip install imutils\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "!pip install pytube --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ghgzl24GnxmK",
        "outputId": "fc239862-d790-4820-f368-c052225a0bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VJQG5Y04nxmL",
        "outputId": "a11b35b1-947f-4319-ad66-775b3a7aa7ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93O99TjcoANx"
      },
      "source": [
        "# 🪡 Fine-tuning YOLONAS on custom dataset\n",
        "\n",
        "## 🏋🏽 The trainer\n",
        "\n",
        "The first thing you need to define in SuperGradients is the Trainer.\n",
        "\n",
        "The trainer is in charge of training, evaluation, saving checkpoints, etc. If you're interested in seeing the source code for the trainer, you can do so [here](https://github.com/Deci-AI/super-gradients/blob/master/src/super_gradients/training/sg_trainer/sg_trainer.py).\n",
        "\n",
        "### ✌🏼 There's two important arguments to the trainer:\n",
        "\n",
        "1) `ckpt_root_dir` - this is the directory where results from all your experiments will be saved\n",
        "\n",
        "2)`experiment_name` - all checkpoints, logs, and tensorboards will be saved in a directory with the name you specify here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nMtzYc_CoAX3",
        "outputId": "d68ef484-bd84-400f-9de2-47b41a963730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f8a959432561>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mCHECKPOINT_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'my_first_yolonas_run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_root_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'super_gradients'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from super_gradients.training import Trainer\n",
        "\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "trainer = Trainer(experiment_name='my_first_yolonas_run', ckpt_root_dir=CHECKPOINT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQjCqyL9vCnQ"
      },
      "source": [
        "# 💾 Datasets and DataLoaders\n",
        "\n",
        "SuperGradients is fully compatible with PyTorch Datasets and Dataloaders, so you can use your dataloaders as is.\n",
        "\n",
        "There are several well-known datasets for object detection, for example:\n",
        "\n",
        "- COCO\n",
        "- Pascal\n",
        "- YOLODarkNet\n",
        "- YOLOv5\n",
        "\n",
        "SuperGradients provides ready-to-use dataloaders for these datasets. If you're interested in learning more about working with `COCOFormatDetectionDataset` and the more general `DetectionDataset` [check out the SuperGradients documentation on this topic](https://docs.deci.ai/super-gradients/docstring/training/datasets/#training.datasets.detection_datasets.coco_detection.COCODetectionDataset)\n",
        "\n",
        "You can learn more about working with SuperGradients datasets, dataloaders, and configuration files [here.](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/Data.md)\n",
        "\n",
        "SuperGradients supports a number of dataset formats, you can learn more about that [here.](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/ObjectDetection.md)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oBojddp2dTY"
      },
      "source": [
        "Start by importing the required modules, which will help you create SuperGradients dataloaders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6voUp-K2qHU"
      },
      "outputs": [],
      "source": [
        "from super_gradients.training import dataloaders\n",
        "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cru1AMcY5AU0"
      },
      "source": [
        "You'll need to load your dataset parameters into a dictionary, specifically defining:\n",
        "\n",
        "- path to the parent directory where your data lives\n",
        "- the child directory names for training, validation, and test (if you have testing set) images and labels\n",
        "- class names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nvw1wr95J8u"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset_params = {\n",
        "    'data_dir':'FallDetection',\n",
        "    'train_images_dir':'train/images',\n",
        "    'train_labels_dir':'train/labels',\n",
        "    'val_images_dir':'val/images',\n",
        "    'val_labels_dir':'val/labels',\n",
        "    'test_images_dir':'test/images',\n",
        "    'test_labels_dir':'test/labels',\n",
        "    'classes': ['Fall-Detected']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgunnL1IIu4v"
      },
      "source": [
        "You pass the values for `dataset_params` into the `dataset_params` argument as shown below.\n",
        "\n",
        "You can also pass PyTorch DataLoaders arguments when instantiating your dataset. Here you'll set `batch_size=16` and `num_workers=2`.\n",
        "\n",
        "Repeat this for the validation and testing datasets, note that for training and testing data we use `coco_detection_yolo_format_val` to instantiate the dataloader.\n",
        "\n",
        "The dataloaders will print warnings when an annotation does not conform to the expected format. This particular dataset has many such annotations, thus the warnings will be muted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVYPTxP32pxF"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "train_data = coco_detection_yolo_format_train(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['train_images_dir'],\n",
        "        'labels_dir': dataset_params['train_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "val_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['val_images_dir'],\n",
        "        'labels_dir': dataset_params['val_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "test_data = coco_detection_yolo_format_val(\n",
        "    dataset_params={\n",
        "        'data_dir': dataset_params['data_dir'],\n",
        "        'images_dir': dataset_params['test_images_dir'],\n",
        "        'labels_dir': dataset_params['test_labels_dir'],\n",
        "        'classes': dataset_params['classes']\n",
        "    },\n",
        "    dataloader_params={\n",
        "        'batch_size':16,\n",
        "        'num_workers':2\n",
        "    }\n",
        ")\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyHwMpQSEQDG"
      },
      "source": [
        "### 🧐 Now inspect the dataset defined earlier.\n",
        "\n",
        "SuperGradients added `transforms` for you. You're free to experiment with these transformations as you please. You can also add in your own transformations from `torchvision.transforms`, `albumentations` or a custom tranformaton."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Os3Wky5carW"
      },
      "outputs": [],
      "source": [
        "train_data.dataset.transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwy2Xq75dvfr"
      },
      "source": [
        "The transforms are in a dictionary, so you'll need to slice it to modify.\n",
        "\n",
        "For example..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8bzD_imcQFj"
      },
      "outputs": [],
      "source": [
        "train_data.dataset.dataset_params['transforms'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY4izlogd294"
      },
      "outputs": [],
      "source": [
        "train_data.dataset.dataset_params['transforms'][1]['DetectionRandomAffine']['degrees'] = 10.42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlV3ZpE-b24i"
      },
      "source": [
        "You can plot a batch of training data with their augmentations applied to see what they look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-u0KiX9bk1X"
      },
      "outputs": [],
      "source": [
        "train_data.dataset.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW4Qg5YuR0mD"
      },
      "source": [
        "# 👩🏽‍🦳 Instantiating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iZihVp_dlwr"
      },
      "outputs": [],
      "source": [
        "from super_gradients.training import models\n",
        "model = models.get('yolo_nas_l',\n",
        "                   num_classes=len(dataset_params['classes']),\n",
        "                   pretrained_weights=\"coco\"\n",
        "                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTe5a7-7efZR"
      },
      "source": [
        "# 📊 Define metrics and training parameters\n",
        "\n",
        "You need to define the training parameters for your training run.\n",
        "\n",
        "Full details about the training parameters can be found [here](https://github.com/Deci-AI/super-gradients/blob/master/src/super_gradients/recipes/training_hyperparams/default_train_params.yaml).\n",
        "\n",
        "\n",
        "### 🚨 There are a few **mandatory** arguments that you must define for training params 🚨\n",
        "\n",
        "- `max_epochs` - Max number of training epochs\n",
        "\n",
        "- `loss` - the loss function you want to use\n",
        "\n",
        "- `optimizer` - Optimizer you will be using\n",
        "\n",
        "- `train_metrics_list` - Metrics to log during training\n",
        "\n",
        "- `valid_metrics_list` - Metrics to log during training\n",
        "\n",
        "- `metric_to_watch` - metric which the model checkpoint will be saved according to\n",
        "\n",
        "You can choose from a variety of `optimizer`'s such as: Adam, AdamW, SGD, Lion, or RMSProps. If you choose to change the defualt parameters of these optimizrs you pass them into `optimizer_params`.\n",
        "\n",
        "\n",
        "### 🧑🏾‍🔬 Integrations with experiment monitoring tools\n",
        "\n",
        "SuperGradients has native integrations with Tensorboard, Weights and Biases, ClearML, and DagsHub.\n",
        "\n",
        "If your favorite monitoring tool is not supported by SuperGradients, you can simply implement a class inheriting from BaseSGLogger that you will then pass to the training parameters.\n",
        "\n",
        "If you're interested in monitoring experiments, you can learn more [in the docs](https://github.com/Deci-AI/super-gradients/blob/0fe46cd39572db34eb83d68e343fed97b8886fe9/documentation/source/experiment_monitoring.md).\n",
        "\n",
        "\n",
        "### 🪄 SuperGradients offers a number of training tricks right out of the box, such as:\n",
        "\n",
        "- Exponential moving average\n",
        "- Zero weight decay on bias and batch normalizatiom\n",
        "- Weight averaging\n",
        "- Batch accumulation\n",
        "- Precise BatchNorm\n",
        "\n",
        "You can read more details about these training tricks [here](https://heartbeat.comet.ml/a-better-way-to-train-your-neural-networks-813b60a5bd6a).\n",
        "\n",
        "If you're interested in building a using a custom metric with SuperGradients you can learn how [here](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/Metrics.md).\n",
        "\n",
        "Note you will have to set number of classes in two places below: `PPYoloELoss` and `DetectionMetrics_050`.\n",
        "\n",
        "You probably noticed that we make use of a post prediction callback, for details on how phase callbacks work in SuperGradients [check out our documentation](https://github.com/Deci-AI/super-gradients/blob/master/documentation/source/PhaseCallbacks.md).\n",
        "\n",
        "### 🔕 Note: I've enabled `silent_mode` so the notebook doesn't get longer than it already is. You should disable it so you can see what SuperGradients outputs during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TnXgisyefds"
      },
      "outputs": [],
      "source": [
        "from super_gradients.training.losses import PPYoloELoss\n",
        "from super_gradients.training.metrics import DetectionMetrics_050\n",
        "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
        "\n",
        "train_params = {\n",
        "    # ENABLING SILENT MODE\n",
        "    'silent_mode': True,\n",
        "    \"average_best_models\":True,\n",
        "    \"warmup_mode\": \"linear_epoch_step\",\n",
        "    \"warmup_initial_lr\": 1e-6,\n",
        "    \"lr_warmup_epochs\": 3,\n",
        "    \"initial_lr\": 5e-4,\n",
        "    \"lr_mode\": \"cosine\",\n",
        "    \"cosine_final_lr_ratio\": 0.1,\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
        "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
        "    \"ema\": True,\n",
        "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
        "    # ONLY TRAINING FOR 10 EPOCHS FOR THIS EXAMPLE NOTEBOOK\n",
        "    \"max_epochs\": 100,\n",
        "    \"mixed_precision\": True,\n",
        "    \"loss\": PPYoloELoss(\n",
        "        use_static_assigner=False,\n",
        "        # NOTE: num_classes needs to be defined here\n",
        "        num_classes=len(dataset_params['classes']),\n",
        "        reg_max=16\n",
        "    ),\n",
        "    \"valid_metrics_list\": [\n",
        "        DetectionMetrics_050(\n",
        "            score_thres=0.1,\n",
        "            top_k_predictions=300,\n",
        "            # NOTE: num_classes needs to be defined here\n",
        "            num_cls=len(dataset_params['classes']),\n",
        "            normalize_targets=True,\n",
        "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
        "                score_threshold=0.01,\n",
        "                nms_top_k=1000,\n",
        "                max_predictions=300,\n",
        "                nms_threshold=0.7\n",
        "            )\n",
        "        )\n",
        "    ],\n",
        "    \"metric_to_watch\": 'mAP@0.50'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8c38zUUefjo"
      },
      "source": [
        "# 🦾 Training the model\n",
        "\n",
        "You've covered a lot of ground so far:\n",
        "\n",
        "✅ Instantiated the trainer\n",
        "\n",
        "✅ Defined your dataset parameters and dataloaders\n",
        "\n",
        "✅ Instantiated a model\n",
        "\n",
        "✅ Set up your training parameters\n",
        "\n",
        "### ⏳ Now, its time to train a model\n",
        "\n",
        "Training a model using a SuperGradients is done using the `trainer`.\n",
        "\n",
        "It's as easy as..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5sKiaH9efp-"
      },
      "outputs": [],
      "source": [
        "trainer.train(model=model,\n",
        "              training_params=train_params,\n",
        "              train_loader=train_data,\n",
        "              valid_loader=val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sP59sDjefzK"
      },
      "source": [
        "# 🏆 Get the best trained model\n",
        "\n",
        "Now that training is complete, you need to get the best trained model.\n",
        "\n",
        "You used checkpoint averaging so the following code will use weights averaged across training runs.\n",
        "\n",
        "If you want to use the best weights, or weights from the last epoch you'd use one of the following in the code below:\n",
        "\n",
        "- best weights: `checkpoint_path = checkpoints/my_first_yolonas_run/ckpt_best.pth`\n",
        "\n",
        "- last weights: `checkpoint_path = checkpoints/my_first_yolonas_run/ckpt_latest.pth`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cXthCX2vgAC"
      },
      "outputs": [],
      "source": [
        "best_model = models.get('yolo_nas_l',\n",
        "                        num_classes=len(dataset_params['classes']),\n",
        "                        checkpoint_path=\"checkpoints/my_first_yolonas_run/ckpt_best.pth\")\n",
        "                        #checkpoint_path=\"checkpoints/my_first_yolonas_run/average_model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gRaxH4dxJAx"
      },
      "source": [
        "# 🧐 Evaluating the best trained model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d112RM240zqb"
      },
      "outputs": [],
      "source": [
        "trainer.test(model=best_model,\n",
        "            test_loader=test_data,\n",
        "            test_metrics_list=DetectionMetrics_050(score_thres=0.1,\n",
        "                                                   top_k_predictions=300,\n",
        "                                                   num_cls=len(dataset_params['classes']),\n",
        "                                                   normalize_targets=True,\n",
        "                                                   post_prediction_callback=PPYoloEPostPredictionCallback(score_threshold=0.01,\n",
        "                                                                                                          nms_top_k=1000,\n",
        "                                                                                                          max_predictions=300,\n",
        "                                                                                                          nms_threshold=0.7)\n",
        "                                                  ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPdjT8Crw9UR"
      },
      "source": [
        "# 🔮 Predicting with the best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG3XCOYfw9d5"
      },
      "outputs": [],
      "source": [
        "#img_url = 'https://www.mynumi.net/media/catalog/product/cache/2/image/9df78eab33525d08d6e5fb8d27136e95/s/e/serietta_usa_2_1/www.mynumi.net-USASE5AD160-31.jpg'\n",
        "#best_model.predict(img_url).show()\n",
        "\n",
        "test_image = 't1.jpg'\n",
        "best_model.predict(test_image).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJO4HGennxmR"
      },
      "source": [
        "# 🎥 Inference on video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pIPoepwnxmS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "input_video_path = \"fallen.mp4\"\n",
        "output_video_path = \"detections.mp4\"\n",
        "#device=0\n",
        "\n",
        "best_model.to(device).predict(input_video_path).save(output_video_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}